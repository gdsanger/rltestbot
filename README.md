# üß† CryptoRL ‚Äì Reinforcement Learning f√ºr Kryptow√§hrungshandel

Ein experimentelles Projekt zum Trainieren eines Reinforcement-Learning-Agenten mit dem Ziel, selbstst√§ndig auf dem Binance-Testnet zu handeln.

## Features
- Binance-Testnet-Integration (BTC/USDT)
- PPO-Agent mit `stable-baselines3`
- Training & Evaluation direkt im Jupyter Notebook
- Live-Marktdaten abrufbar
- Custom Gym-Environment `BinanceTradingEnv` f√ºr Echtzeitdaten
- Logging der Trades in `trading_log.csv`

## Voraussetzungen

```bash
pip install -r requirements.txt
```

Zus√§tzlich wird das MEXC SDK ben√∂tigt. Eine Kopie liegt bereits unter
`mexc/mexc_sdk/src` bei. Alternativ kannst du das offizielle Repository
klonen und lokal installieren:

```bash
git clone https://github.com/MEXCofficial/mexc-api-sdk.git
pip install -e mexc-api-sdk/dist/python
```

Wenn du die beigelegte Version verwendest, gen√ºgt es die Umgebungsvariable
`MEXC_SDK_PATH` auf `mexc/mexc_sdk/src` zu setzen. Das Skript pr√ºft diesen
Pfad automatisch.

Alternativ kannst du den Pfad `mexc-api-sdk/dist/python` √ºber die
Umgebungsvariable `PYTHONPATH` einbinden.

## Start

```bash
jupyter lab
```

Dann √∂ffne `CryptoRL_Starter_with_Agent.ipynb` und folge den Schritten.

### Nutzung des Environments

```python
from binance_env import BinanceTradingEnv
env = BinanceTradingEnv()
obs = env.reset()
```

### Training eines PPO-Agenten

Neben dem Notebook kann ein Agent auch per Skript trainiert werden. Das Skript
`train_agent.py` verwendet das vereinfachte `CryptoEnv`, welches nun echte
OHLCV-Daten vom Binance-Testnet nutzt, und speichert nach 100.000 Schritten das
Modell.

```bash
python train_agent.py
```

Vor dem Start sollten die Umgebungsvariablen `BINANCE_API_KEY` und
`BINANCE_API_SECRET` mit den Zugangsdaten des Testnet-Accounts gesetzt sein.

F√ºr die MEXC-Integration werden die Schl√ºssel ebenfalls √ºber Umgebungsvariablen
geladen. Lege dazu eine `.env`-Datei im Projektverzeichnis mit
`MEXC_API_KEY` und `MEXC_API_SECRET` an. Die Module laden diese Werte beim
Start automatisch.

### Regelm√§√üiges Finetuning

Um ein vorhandenes Modell weiter zu verbessern, kann `mexc/finetune_agent.py`
genutzt werden. Das Skript l√§dt den Agenten f√ºr das angegebene Handelspaar und
f√ºhrt weitere Trainingsschritte aus.

```bash
python mexc/finetune_agent.py --symbol ATOMUSDC --timesteps 50000
```

Dieses Kommando l√§sst sich beispielsweise t√§glich per Cron ausf√ºhren, um den
Agenten aktuell zu halten.



## Equity-Kurve berechnen

Das Modul `equity_curve.py` bietet die Funktion `calculate_equity_curve`, um eine
Portfolio-Kurve aus dem gespeicherten `trading_log.csv` zu erzeugen. Dabei wird
folgende Formel verwendet:

```
Equity = Startkapital + realisierte Gewinne + (offene Position √ó aktueller Preis - Einstiegspreis)
```

Beispiel:

```python
from equity_curve import calculate_equity_curve
curve = calculate_equity_curve("trading_log.csv")
curve.plot()
```

Die Close-Preise werden automatisch √ºber `fetch_recent_candles` von Binance
abgerufen. Alternativ k√∂nnen eigene Preisdaten √ºbergeben werden.

### Buy&Hold Benchmark

Um die Agent-Performance einordnen zu k√∂nnen, bietet `equity_curve.py` die
Funktion `compare_with_buy_and_hold`. Dabei wird zu Beginn das gesamte
Startkapital in BTC investiert und der Kursverlauf als Benchmark verfolgt.

```python
from equity_curve import compare_with_buy_and_hold
fig = compare_with_buy_and_hold("trading_log.csv", return_plot=True)
fig.show()
```

## Haftungsausschluss

**Dies ist kein Finanzrat. Nur zu Forschungs- und Lernzwecken.**
